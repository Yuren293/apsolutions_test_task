# apsolutions_test_task

## Интерпретация задачи
Если переводить формулировку с языка бизнеса на язык ml, то нужно решить задачу бинарной классификации. При этом нужно прогнозировать вероятность принадлежности каждог
о клиента к классу 1 (займ одобрен) и далее давать метку 1 35% клиентам и более. Формулировку ‘При банкротстве среди одобренных не выше 15%’ можно понять так:
Нужно минимизировать количество False Positive значений модели, поэтому в качестве метрики возьмем Precision (точность) которая минимизирует FP.
При этом значение метрики должно быть не ниже 0.85. Попробую сначала точно определить клиентов, которым кредит одобрят, а затем добрать потенциальных банкротов по
вероятностям принадлежности к классу 1, которые чуть меньше порога классификации.

## Выводы по первоначальному обзору данных
Были получены размеченные данные о выдаче/не выдаче займов клиентам и дополнительные данные о клиентах, которые либо отказались от кредита либо им его не одобрили
финансовые организации. Признаковое пространство обоих файлов одинаковое, поэтому было принято решение объединить размеченные данные для обучения с данными о 
невыданных займах. В дальнейшем выяснилось, что объединение данных ухудшило результаты всех моделей. В итоге для обучения, валидации и тестирования был использован 
только первый датасет.

Общие выводы:
1. Во многих столбцах дублируются значения, но это допустимо из-за специфики данных
2. В 18 признаках были найдены пропуски. Больше всего их в столбцах ‘ratio_overdue_loans_3_to_12’, ‘ratio_mean_delay_3_to_12’, ‘ratio_history_1’,
’ratio_sum_outstanding_to_open_sum, ‘ratio_history_3’.
3. Найдено 407 (197 для необогащенного) дубликатов по строкам, которые я удалять не буду т.к. такие совпадения в кредитном поведении хоть и немногочисленны,
но вполне вероятны.
4. overdue_loans_12 и overdue_loans_3 могут быть удалены, так как заполнены одним значением
5. ratio_overdue_loans_3_to_12 содерыт лишь пропуски и значение 0, поэтому его тоже лучше удалить
6. Природа пропусков датасета для обучения, взятого отдельно от датасета невыданных займов и соединенных вместе данных похожа
7. Буду заменять пропуски средним значением, т.к. постраюсь избавиться от всех выбросов, заменив их медианным значением
8. Так как признаков много, я не буду удалять строки, где есть хотя бы один выброс. Вместо этого буду заменять выбросы медианным значением


## Вывод по отбору признаков
Был использован Sequential Forward Selection. Алгоритм перебрал комбинации признаковых пространств разных размеров и для каждого построил модель cлучаного леса. Результатом стал набор признаков, которые дали наилучший результат модели. Однако в ходе обучения моделей ниже я пришел к выводу, что использование данной комбинации не дало ощутимо хороших результатов. В ходе перебора гиперпараметов XGBoost-а на данном признаковом пространстве модель обучилась хуже, чем с использованием практически всех признаков (за исключением тех, что я удалил на этапе предобработки). К сожалению пребрать комбинации числом более 30 признаков не представилось возможным из-за времени вычислений даже на CPU c 8 ядрами с частотой 5ггц. 
Для Выбора наиболее значимых признаков, повлиявших на прогноз, быыли взяты feature_importances  лучшей модели (XGBoostClassifier). 45 признаков имеют коэффициент вклада в модель более 0.5. В моем случае модель стермится минимизировать FP, чтобы по возможности наиболее точно определять людей, которым можно дать кредит.
Наибольший вклад внесли признаки is_type_micro_12, micro_loans_active_100, micro_loans_active_100. Далее идут is_active_1, ratio_mean_delay_3_to_12 и другие

## Результаты обучения
1. RandomForest - n_estimators = 1000,
 min_samples_split = 2,
 min_samples_leaf = 1,
 max_features ='auto',
 max_depth =50,
 bootstrap=False)
precision - 0.52. Из 6380 дает кредиты только 240 (из 1770 истинных меток 1)

---------------------------
2. RandomForest - n_estimators = 500
precision - 0.58. Из 6380 дает кредиты только 180 (из 1770 истинных меток 1)

----------------------------
3. RandomForest - n_estimators = 500 (не заменял выбросы в аномальных признаках на медианы, в остальных признаках заменял)
precision - 0.52. ИЗ 6380 дает кредиты только 252 (из 1770 истинных меток 1)

----------------------------
Смог добиться precision в 0.55 с помощью GridSearchCV и XGBoost, максимизируя precision и не трогая выбросы в признаках с аномальным распределением. Однако, такая точность была получена только за счет снижения колчичества предсказанных единиц (51 клиент)
Смог добиться precision в 0.41  с помощью GridSearchCV и XGBoost, максимизируя balanced_accuracy и не трогая выбросы в признаках с аномальным распределением. Однако, получил 885 предсказанных единиц

4. (Лучший результат)

XGBoost (лучшие параметры отображены в коде). максимизировал Precision
precision - 0.76 (88 истинных меток 1)

----------------------------

Чтобы получить количество банкротов не более 15 % из общего числа людей, которым нужно дать кредит, я максимизировал Precision. Лучший результат показал Precision = 67%. Т.е. в моем случае 33% будут являться банкротами из всех, кому дали кредит. Т.к. я максимизировал Preciscion и моей задумкой было сначала точно определить клиентов, которым кредит одобрят, а затем добрать потенциальных банкротов по вероятностям принадлежности к классу 1, которые чуть менее порога классификации.
    К сожалению, при изменении порога Precision начала уменьшаться до 50% и ниже, что эквивалентно константной модели. Поэтому порог я решил оставить как есть - 50%. Однако при текущем соотношении кол-ва 1 и 0 в данных НЕЛЬЗЯ получть требуемый в задании результат при разделении данных на train valid и test.
Доказательстово: в тестовой выборке 6380 наблюдений, их них 1770 имеют метку 1. По заданию нужно 'построить базовую модель прогнозирования банкротства, одобряющую не менее 35% клиентов при банкротстве среди одобренных не выше 15%.'. 35% от тестовой выборки это 2233.0 наблюдений, из которых минимум 1980 (минимум 85% по заданию должны иметь истинную метку 1) должны иметь истинную метку 1. Однако в тестовой выборке у нас всего 1770 наблюдений с 1.
    Таким образом, для построения качественных резултатов прогноза необходимо получить больше данных о клиентах, кому кредит был одобрен. Можно попытаться сделать upsampling тестовой выборки, чтобы получить требуемый результат, но это уже подгон под ответ
    
 ## Очень скоромные рекомндации 
1. Нужно больше данных о выданных кредитах
2. Часть признаков практически не влияет на прогнозирование целевой переменной (смотреть выводы предобработки данных), данные о них можно не собирать
3. В данных много пропущенных значений и выбросов, которые можно обрабатывать сразу на этапе сбора данных
